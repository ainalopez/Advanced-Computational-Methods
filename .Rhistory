if (is.null(sigma)) { sigma <- diag(features) }
if (is.null(mus)) { mus <- rep(0, features) }
# Simulate points from a bivariate normal
phi <- rmvnorm(n, mean = mus, sigma = sigma)
# Decide which belong to each cluster
rad <- (2 ** (features - 1) * gamma(1 + features / 2) /
(pi ** (features / 2))) ** (1 / features)
ones <- apply(phi, 1, function(x) { jitter(sum((x - mus) ** 2)) }) > rad ** 2
#ones <- apply(phi, 1, function(x) { sum((x - mus) ** 2) }) > rad ** 2
category <- rep(0, length = n)
category[ones] <- 1
# Build the final data frame
new.phi <- cbind.data.frame(phi, as.character(category))
new.phi[, 3] <- as.factor(new.phi[, 3])
colnames(new.phi) <- c("x1", "x2", 'y')
# Save the data in a .csv file
if (saveData) {
write.csv(new.phi, file = 'dataset.csv', row.names = FALSE)
cat('Saved file:', paste0(getwd(), '/dataset.csv'), '\n')
}
# Plot
if (savePlot) {
unlink('dataPlot.pdf')
cairo_pdf('dataPlot.pdf')
plot1 <-
ggplot(data = new.phi, aes(x = x1, y = x2,
colour = y, fill = y)) +
geom_point() +
xlab('x1') +
ylab('x2') +
theme_bw()
print(plot1)
dev.off()
cat('Saved plot:', paste0(getwd(), '/dataPlot.pdf'), '\n')
}
# End
return(new.phi)
}  # END OF SCRIPT
if (!require("mvtnorm")) install.packages("mvtnorm")
if (!require("ggplot2")) install.packages("ggplot2")
dataset <- genSun(n = 400, features = 2, seed = 1111, saveData = FALSE, savePlot = FALSE)
features <- as.matrix(cbind(dataset$x1,dataset$x2))
labels   <- as.numeric(as.vector(dataset$y))
# compute KNN
knn.res <- kNN(features, labels, k = 3, p = 1, type = "train")
df <- data.frame(dataset, knn.res)
xmin <- min(dataset$x1); xmax <- max(dataset$x1)
ymin <- min(dataset$x2); ymax <- max(dataset$x2)
x1.n     <-seq(xmin, xmax, len=20)
x2.n     <-seq(ymin, ymax, len=20)
x1.new <-rep(x1.n, 20)
x2.new <-rep(x2.n, rep(20,20))
knn.res.db <- kNN(features, labels, k = 1, p = 1, memory = cbind(x1.new,x2.new), type = "predict")
pred <-knn.res.db$predLabels
ggplot(data = dataset, aes(x = x1, y = x2, colour = labels, fill = labels)) +
geom_point() +
xlab('x1') +
ylab('x2') +
stat_contour( aes(x = x1.new, y = x2.new, z = pred, bins = 1)) +
theme_bw()
if (!require("mvtnorm")) install.packages("mvtnorm")
if (!require("ggplot2")) install.packages("ggplot2")
dataset <- genSun(n = 625, features = 2, seed = 1111, saveData = FALSE, savePlot = FALSE)
features <- as.matrix(cbind(dataset$x1,dataset$x2))
labels   <- as.numeric(as.vector(dataset$y))
# compute KNN
knn.res <- kNN(features, labels, k = 3, p = 1, type = "train")
df <- data.frame(dataset, knn.res)
xmin <- min(dataset$x1); xmax <- max(dataset$x1)
ymin <- min(dataset$x2); ymax <- max(dataset$x2)
x1.n     <-seq(xmin, xmax, len=25)
x2.n     <-seq(ymin, ymax, len=25)
x1.new <-rep(x1.n, 25)
x2.new <-rep(x2.n, rep(25,25))
knn.res.db <- kNN(features, labels, k = 1, p = 1, memory = cbind(x1.new,x2.new), type = "predict")
pred <-knn.res.db$predLabels
ggplot(data = dataset, aes(x = x1, y = x2, colour = labels, fill = labels)) +
geom_point() +
xlab('x1') +
ylab('x2') +
stat_contour( aes(x = x1.new, y = x2.new, z = pred, bins = 1)) +
theme_bw()
ggplot(data = dataset, aes(x = x1, y = x2, colour = labels, fill = labels)) +
geom_point() +
xlab('x1') +
ylab('x2') +
stat_contour( aes(x = x1.new, y = x2.new, z = pred, bins = 10)) +
theme_bw()
training <- read.csv(file = "Desktop/ML_competition/Data/news_popularity_training.csv")
training <- read.csv(file = "Desktop/ML_competition/Data/news_popularity_training.csv")
test     <- read.csv(file = "Desktop/ML_competition/Data/news_popularity_test.csv")
# Popularity 5: less samples
# Keep only predictive data
training.p <- train# ing[c(-1, -2, -3)]
training.p <- training[c(-1, -2, -3)]
test.p     <- test[c(-1, -2, -3)]
training.p <- train
n <- dim(training.p)[1]
training.p <- training[c(-1, -2, -3)]
set.seed(123)
train_ind <- sample(n, size = (n/2+500))
training.p1  <- training.p[train_ind,]
training.p2 <- training.p[-train_ind,-60]
training.p2.label  <- training.p[-train_ind,60]
var(c(1,2,2,1,3,3,1,1,2))
var(c(1,5,5,5,5,5,1,1,1))
noe <- apply(training.p,2,norm<-function(x){return (x/sum(x)})
noe <- apply(training.p,2, function(x){return(x/sum(x)})
noe <- apply(training.p, 2, function(x) (x/sum(x))
{}
noe <- apply(training.p, 2, function(x) (x/sum(x)) )
apply(noe, 2, var)
glm(factor(popularity) ~ . ,
data=training.p1)
lm(factor(popularity) ~ . ,
data=training.p1)
forest <- randomForest(factor(popularity) ~ . ,
data=training.p1,
#mtry = 10,
#sampsize=c(2000,2000,2000,516,k),
cutoff=c(0.125, 0.125, 0.20, 0.25, 0.3),
replace = FALSE,
importance = TRUE, ntree = 300)
library(randomForest)
forest <- randomForest(factor(popularity) ~ . ,
data=training.p1,
#mtry = 10,
#sampsize=c(2000,2000,2000,516,k),
cutoff=c(0.125, 0.125, 0.20, 0.25, 0.3),
replace = FALSE,
importance = TRUE, ntree = 300)
prediction <- predict(forest, training.p2)#testing)
table(prediction, training.p2.label)
dif <- as.numeric(prediction)-training.p2.label#round(svm.pred)-training.p2$popularity
eq  <- 0
for(i in 1:length(dif)){
if(dif[i] == 0){
eq <- eq +1
}
}
dif <- as.numeric(prediction)-training.p2.label#round(svm.pred)-training.p2$popularity
dif
prediction <- predict(forest, training.p2)#testing)
forest
prediction <- predict(forest, training.p2)#testing)
table(prediction, training.p2.label)
length(prediction)
length(training.p2.label)
training.p2.label  <- training.p[-train_ind,60]
training.p2.label
training.p2
training.p <- training[c(-1, -2, -3)]
training.p2.label  <- training.p[-train_ind,60]
training.p2.label
training.p2.label  <- training.p[-train_ind,59]
table(prediction, training.p2.label)
dif <- as.numeric(prediction)-training.p2.label#round(svm.pred)-training.p2$popularity
eq  <- 0
for(i in 1:length(dif)){
if(dif[i] == 0){
eq <- eq +1
}
}
eq/length(dif) *100
training.p11<- training.p1[-c(21,22,22,27,28,29),]
forest <- randomForest(factor(popularity) ~ . ,
data=training.p11,
#mtry = 10,
#sampsize=c(2000,2000,2000,516,k),
cutoff=c(0.125, 0.125, 0.20, 0.25, 0.3),
replace = FALSE,
importance = TRUE, ntree = 300)
training.p22<- training.p2[-c(21,22,22,27,28,29),]
prediction <- predict(forest, training.p22)#testing)
table(prediction, training.p2.label)
# solution <- data.frame(Id = test$id, Popularity = as.numeric(prediction))
# write.csv(solution, file = "predictions_rf.csv", row.names = FALSE)
dif <- as.numeric(prediction)-training.p2.label#round(svm.pred)-training.p2$popularity
eq  <- 0
for(i in 1:length(dif)){
if(dif[i] == 0){
eq <- eq +1
}
}
eq/length(dif) *100
table(prediction, training.p2.label)
length(training.p2.label)
length(prediction)
training.p11<- training.p1[-c(21,22,22,27,28,29)]
str(training.p11)
dim(training.p11)
dim(training.p22)
training.p11<- training.p1[-c(21,22,22,27,28,29)]
training.p22<- training.p2[-c(21,22,22,27,28,29)]
forest <- randomForest(factor(popularity) ~ . ,
data=training.p11,
#mtry = 10,
#sampsize=c(2000,2000,2000,516,k),
cutoff=c(0.125, 0.125, 0.20, 0.25, 0.3),
replace = FALSE,
importance = TRUE, ntree = 300)
# 300: 51.02
# 300 - columna
####predictions####
prediction <- predict(forest, training.p22)#testing)
table(prediction, training.p2.label)
# solution <- data.frame(Id = test$id, Popularity = as.numeric(prediction))
# write.csv(solution, file = "predictions_rf.csv", row.names = FALSE)
dif <- as.numeric(prediction)-training.p2.label#round(svm.pred)-training.p2$popularity
eq  <- 0
for(i in 1:length(dif)){
if(dif[i] == 0){
eq <- eq +1
}
}
eq/length(dif) *100
training.p11<- training.p1[-c(21,22,22,27,28)]
training.p22<- training.p2[-c(21,22,22,27,28)]
forest <- randomForest(factor(popularity) ~ . ,
data=training.p11,
#mtry = 10,
#sampsize=c(2000,2000,2000,516,k),
cutoff=c(0.125, 0.125, 0.20, 0.25, 0.3),
replace = FALSE,
importance = TRUE, ntree = 300)
# 300: 51.02
# 300 - 50.55 columna
####predictions####
prediction <- predict(forest, training.p22)#testing)
table(prediction, training.p2.label)
# solution <- data.frame(Id = test$id, Popularity = as.numeric(prediction))
# write.csv(solution, file = "predictions_rf.csv", row.names = FALSE)
dif <- as.numeric(prediction)-training.p2.label#round(svm.pred)-training.p2$popularity
eq  <- 0
for(i in 1:length(dif)){
if(dif[i] == 0){
eq <- eq +1
}
}
eq/length(dif) *100
training.p11<- training.p1[-c(21,22,22,27)]
training.p22<- training.p2[-c(21,22,22,27)]
forest <- randomForest(factor(popularity) ~ . ,
data=training.p11,
#mtry = 10,
#sampsize=c(2000,2000,2000,516,k),
cutoff=c(0.125, 0.125, 0.20, 0.25, 0.3),
replace = FALSE,
importance = TRUE, ntree = 300)
# 300: 51.02
# 300 - 50.55 columna (29)
# 300 - 50.71 columna (-29)
####predictions####
prediction <- predict(forest, training.p22)#testing)
table(prediction, training.p2.label)
# solution <- data.frame(Id = test$id, Popularity = as.numeric(prediction))
# write.csv(solution, file = "predictions_rf.csv", row.names = FALSE)
dif <- as.numeric(prediction)-training.p2.label#round(svm.pred)-training.p2$popularity
eq  <- 0
for(i in 1:length(dif)){
if(dif[i] == 0){
eq <- eq +1
}
}
eq/length(dif) *100
forest <- randomForest(factor(popularity) ~ . ,
data=training.p1,
#mtry = 10,
#sampsize=c(2000,2000,2000,516,k),
#cutoff=c(0.125, 0.125, 0.20, 0.25, 0.3),
replace = FALSE,
importance = TRUE, ntree = 300)
# 300: 51.02
# 300 - 50.55 columna (29)
# 300 - 50.71 columna -c(21,22,22,27,28)
# 300 -  50.62069columna -c(21,22,22,27)
####predictions####
prediction <- predict(forest, training.p2)#testing)
table(prediction, training.p2.label)
# solution <- data.frame(Id = test$id, Popularity = as.numeric(prediction))
# write.csv(solution, file = "predictions_rf.csv", row.names = FALSE)
dif <- as.numeric(prediction)-training.p2.label#round(svm.pred)-training.p2$popularity
eq  <- 0
for(i in 1:length(dif)){
if(dif[i] == 0){
eq <- eq +1
}
}
eq/length(dif) *100
training.p11<- training.p1[-c(21,22,22,27,28)]
training.p22<- training.p2[-c(21,22,22,27,28)]
forest <- randomForest(factor(popularity) ~ . ,
data=training.p11,
#mtry = 10,
#sampsize=c(2000,2000,2000,516,k),
#cutoff=c(0.125, 0.125, 0.20, 0.25, 0.3),
replace = FALSE,
importance = TRUE, ntree = 300)
# 300: 51.26
# 300 - 50.55 columna (29)
# 300 - 50.71 columna -c(21,22,22,27,28)
# 300 -  50.62069columna -c(21,22,22,27)
####predictions####
prediction <- predict(forest, training.p22)#testing)
table(prediction, training.p2.label)
# solution <- data.frame(Id = test$id, Popularity = as.numeric(prediction))
# write.csv(solution, file = "predictions_rf.csv", row.names = FALSE)
dif <- as.numeric(prediction)-training.p2.label#round(svm.pred)-training.p2$popularity
eq  <- 0
for(i in 1:length(dif)){
if(dif[i] == 0){
eq <- eq +1
}
}
eq/length(dif) *100
training.p11<- training.p1[-c(21)]
training.p22<- training.p2[-c(21)]
forest <- randomForest(factor(popularity) ~ . ,
data=training.p11,
#mtry = 10,
#sampsize=c(2000,2000,2000,516,k),
#cutoff=c(0.125, 0.125, 0.20, 0.25, 0.3),
replace = FALSE,
importance = TRUE, ntree = 300)
# 300: 51.26
# 300 - 50.62 columna -c(21,22,22,27,28)
####predictions####
prediction <- predict(forest, training.p22)#testing)
table(prediction, training.p2.label)
# solution <- data.frame(Id = test$id, Popularity = as.numeric(prediction))
# write.csv(solution, file = "predictions_rf.csv", row.names = FALSE)
dif <- as.numeric(prediction)-training.p2.label#round(svm.pred)-training.p2$popularity
eq  <- 0
for(i in 1:length(dif)){
if(dif[i] == 0){
eq <- eq +1
}
}
eq/length(dif) *100
training.p11<- training.p1[-c(22)]
training.p22<- training.p2[-c(22)]
forest <- randomForest(factor(popularity) ~ . ,
data=training.p11,
#mtry = 10,
#sampsize=c(2000,2000,2000,516,k),
#cutoff=c(0.125, 0.125, 0.20, 0.25, 0.3),
replace = FALSE,
importance = TRUE, ntree = 300)
# 300: 51.26
# 300 - 50.62 columna -c(21,22,23,27,28)
# 300 - 51.17 columna -c(21)
# 300 - 51.17 columna -c(22)
# 300 - 51.17 columna -c(23)
####predictions####
prediction <- predict(forest, training.p22)#testing)
table(prediction, training.p2.label)
# solution <- data.frame(Id = test$id, Popularity = as.numeric(prediction))
# write.csv(solution, file = "predictions_rf.csv", row.names = FALSE)
dif <- as.numeric(prediction)-training.p2.label#round(svm.pred)-training.p2$popularity
eq  <- 0
for(i in 1:length(dif)){
if(dif[i] == 0){
eq <- eq +1
}
}
eq/length(dif) *100
training.p11<- training.p1[-c(23)]
training.p22<- training.p2[-c(23)]
forest <- randomForest(factor(popularity) ~ . ,
data=training.p11,
#mtry = 10,
#sampsize=c(2000,2000,2000,516,k),
#cutoff=c(0.125, 0.125, 0.20, 0.25, 0.3),
replace = FALSE,
importance = TRUE, ntree = 300)
# 300: 51.26
# 300 - 50.62 columna -c(21,22,23,27,28)
# 300 - 51.17 columna -c(21)
# 300 - 50.73 columna -c(22)
# 300 -  columna -c(23)
# 300 -  columna -c(27)
# 300 -  columna -c(28)
# 300 -  columna -c(29)
####predictions####
prediction <- predict(forest, training.p22)#testing)
table(prediction, training.p2.label)
# solution <- data.frame(Id = test$id, Popularity = as.numeric(prediction))
# write.csv(solution, file = "predictions_rf.csv", row.names = FALSE)
dif <- as.numeric(prediction)-training.p2.label#round(svm.pred)-training.p2$popularity
eq  <- 0
for(i in 1:length(dif)){
if(dif[i] == 0){
eq <- eq +1
}
}
eq/length(dif) *100
install.packages("rrf")
install.packages("RRF")
library(RRF)
forest <- rrf(factor(popularity) ~ . ,
data=training.p1,
#mtry = 10,
#sampsize=c(2000,2000,2000,516,k),
#cutoff=c(0.125, 0.125, 0.20, 0.25, 0.3),
replace = FALSE,
importance = TRUE, ntree = 300)
forest <- RRF(factor(popularity) ~ . ,
data=training.p1,
#mtry = 10,
#sampsize=c(2000,2000,2000,516,k),
#cutoff=c(0.125, 0.125, 0.20, 0.25, 0.3),
replace = FALSE,
importance = TRUE, ntree = 300)
forest$importance
str(forest)
forest$confusion
prediction <- predict(forest$forest, training.p22)#testing)
forest$feaSet
training.p11<- training.p1[-c(14, 15, 36)]
training.p22<- training.p2[-c(14,15,36)]
forest <- randomForest(factor(popularity) ~ . ,
data=training.p1,
#mtry = 10,
#sampsize=c(2000,2000,2000,516,k),
#cutoff=c(0.125, 0.125, 0.20, 0.25, 0.3),
replace = FALSE,
importance = TRUE, ntree = 300)
# 300: 51.26
# 300 - 50.62 columna -c(21,22,23,27,28)
# 300 - 51.17 columna -c(21)
# 300 - 50.73 columna -c(22)
# 300 -  50.79 columna -c(23)
# 300 -  columna -c(27)
# 300 -  columna -c(28)
# 300 -  columna -c(29)
####predictions####
prediction <- predict(forest$forest, training.p22)#testing)
table(prediction, training.p2.label)
# solution <- data.frame(Id = test$id, Popularity = as.numeric(prediction))
# write.csv(solution, file = "predictions_rf.csv", row.names = FALSE)
dif <- as.numeric(prediction)-training.p2.label#round(svm.pred)-training.p2$popularity
eq  <- 0
for(i in 1:length(dif)){
if(dif[i] == 0){
eq <- eq +1
}
}
eq/length(dif) *100
prediction <- predict(forest, training.p22)#testing)
forest
prediction <- predict(forest, training.p22)#testing)
library(randomForest)
prediction <- predict(forest, training.p22)#testing)
library("class")
setwd("Desktop/Advanced Computational methods/Advanced-Computational-Methods/")
training <- read.csv("PS4/MNIST/MNIST_training.csv", header = FALSE)
test     <- read.csv("PS4/MNIST/MNIST_test.csv", header = FALSE)
label <- training[,1]
feat  <- training[,2:257]
# Choose k and p using 4-Fold Cross Validation
k <- rep(seq(31,100,2))
lk <- length(k)
# 4 fold Cross-Validation
n <- nrow(training)
fold <- sample(1:4, n, replace=TRUE)
acc <- rep (NA, lk)
cvpred <- matrix(NA,nrow=n ,ncol=ncol(training))
i <- 1
l <- knn(train = feat[fold!=i, ], test = feat[fold==i, ], cl = label[fold!=i], k = 801)
l <- knn(train = feat[fold!=i, ], test = feat[fold==i, ], cl = label[fold!=i], k = 701)
l <- knn(train = feat[fold!=i, ], test = feat[fold==i, ], cl = label[fold!=i], k = 601)
l <- knn(train = feat[fold!=i, ], test = feat[fold==i, ], cl = label[fold!=i], k = 501)
l <- knn(train = feat[fold!=i, ], test = feat[fold==i, ], cl = label[fold!=i], k = 401)
l <- as.numeric(l)
(1/length(l)) * sum(label[fold==i] == l)*100
table(label[fold==i], l)
l <- knn(train = feat[fold!=i, ], test = feat[fold==i, ], cl = label[fold!=i], k = 401)
sum(label[fold==i] == l
)
length(l)
(1/length(l)) * sum(label[fold==i] == l)*100
l <- knn(train = feat[fold!=i, ], test = feat[fold==i, ], cl = label[fold!=i], k = 451)
(1/length(l)) * sum(label[fold==i] == l)*100
l <- knn(train = feat[fold!=i, ], test = feat[fold==i, ], cl = label[fold!=i], k = 101)
(1/length(l)) * sum(label[fold==i] == l)*100
k <- rep(seq(31,201,2))
lk <- length(k)
# 4 fold Cross-Validation
n <- nrow(training)
fold <- sample(1:4, n, replace=TRUE)
acc <- rep (NA, lk)
cvpred <- matrix(NA,nrow=n ,ncol=ncol(training))
for (h in 1:lk){
ac <- rep(NA,4)
for (i in 1:4){
l <- knn(train = feat[fold!=i, ], test = feat[fold==i, ], cl = label[fold!=i], k = 101)
ac[i] <- (1/length(l)) * sum(label[fold==i] == l)*100
}
acc[h] <- mean(ac)
}
acc
k
k <- rep(seq(201,501,2))
for (h in 1:lk){
ac <- rep(NA,4)
for (i in 1:4){
l <- knn(train = feat[fold!=i, ], test = feat[fold==i, ], cl = label[fold!=i], k = 101)
ac[i] <- (1/length(l)) * sum(label[fold==i] == l)*100
}
acc[h] <- mean(ac)
}
acc
